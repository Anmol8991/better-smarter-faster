{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from graph_utils import Graph\n",
    "from agent import Agent\n",
    "from predator import Predator\n",
    "from prey import Prey\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import probability as prob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "def create_adj_matrix(adjacency_list) -> list:\n",
    "\n",
    "    matrix = np.zeros((len(adjacency_list), len(adjacency_list)))\n",
    "\n",
    "    for node in adjacency_list.keys():\n",
    "        for i in adjacency_list[node]:\n",
    "            matrix[node][i] = 1\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def visualise_graph(networkx_graph,color_map,filename):  \n",
    "    pos = nx.nx_agraph.graphviz_layout(networkx_graph, prog=\"neato\") # k=5/math.sqrt(G.order())\n",
    "    nx.draw(networkx_graph, node_color = color_map, pos=pos, with_labels=True)\n",
    "\n",
    "    # Just save a PNG for the plot\n",
    "    plt.gcf().set_size_inches(11.2775330396, 7.04845814978) # The MacbookPro 13.3 inches size\n",
    "    plt.savefig(filename, dpi=227) # The MacbookPro 13.3 inches dpi\n",
    "    plt.show()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_vertices = 50\n",
    "# number_of_graphs = 5\n",
    "\n",
    "# for i in range(number_of_graphs):\n",
    "#     G = Graph()\n",
    "#     G.create_graph_tcol(total_vertices)\n",
    "    \n",
    "\n",
    "#     file_name = \"./Graphs/graph\" + str(i)  + '/graph.pkl'\n",
    "#     with open(file_name, 'rb') as f:\n",
    "#         loaded_dict = pickle.dump(G.graph,f)\n",
    "    \n",
    "#     # Store picture of graph\n",
    "#     file_name2 = \"./Graphs/graph\" + str(i)  + '/output.png'\n",
    "#     adj_matrix = create_adj_matrix(G.graph)\n",
    "#     networkx_G = nx.from_numpy_matrix(adj_matrix)\n",
    "#     color_map = ['lightblue' for i in range(50)]\n",
    "\n",
    "#     visualise_graph(networkx_G,color_map,file_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [1, 49, 2], 1: [0, 2, 4], 2: [1, 3, 0], 3: [2, 4, 6], 4: [3, 5, 1], 5: [4, 6, 7], 6: [5, 7, 3], 7: [6, 8, 5], 8: [7, 9, 13], 9: [8, 10, 12], 10: [9, 11, 15], 11: [10, 12, 14], 12: [11, 13, 9], 13: [12, 14, 8], 14: [13, 15, 11], 15: [14, 16, 10], 16: [15, 17, 19], 17: [16, 18, 20], 18: [17, 19, 22], 19: [18, 20, 16], 20: [19, 21, 17], 21: [20, 22, 25], 22: [21, 23, 18], 23: [22, 24, 28], 24: [23, 25, 29], 25: [24, 26, 21], 26: [25, 27, 31], 27: [26, 28, 30], 28: [27, 29, 23], 29: [28, 30, 24], 30: [29, 31, 27], 31: [30, 32, 26], 32: [31, 33, 34], 33: [32, 34, 35], 34: [33, 35, 32], 35: [34, 36, 33], 36: [35, 37, 39], 37: [36, 38, 40], 38: [37, 39, 43], 39: [38, 40, 36], 40: [39, 41, 37], 41: [40, 42], 42: [41, 43, 46], 43: [42, 44, 38], 44: [43, 45, 48], 45: [44, 46, 49], 46: [45, 47, 42], 47: [46, 48], 48: [47, 49, 44], 49: [48, 0, 45]}\n"
     ]
    }
   ],
   "source": [
    "graph_number = 0\n",
    "file_name = \"./Graphs/graph\" + str(graph_number)  + '/graph.pkl'\n",
    "G = Graph()\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)\n",
    "    G.graph = loaded_dict\n",
    "\n",
    "print(G.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def update_prey_trans_matrix(graph: Graph) -> None:\n",
    "        \"\"\"\n",
    "        Updates prey transition matrix P(i, j) = Probability of prey at node i at (t + 1) given prey was at node j at (t) i.e. [j -> i]\n",
    "        \"\"\"\n",
    "        graph_nodes = graph.node_list()\n",
    "\n",
    "        prey_transition_matrix = np.zeros((len(graph_nodes), len(graph_nodes)))\n",
    "\n",
    "        for jnode in graph_nodes:\n",
    "\n",
    "            neighbors = list(graph.neighbors(jnode))\n",
    "            prob_each_neighbor = 1 / (len(neighbors) + 1)\n",
    "    \n",
    "            # When prey stays at the same node\n",
    "            prey_transition_matrix[jnode, jnode] = prob_each_neighbor\n",
    "\n",
    "            # When prey moves to a different node\n",
    "            for inode in neighbors:\n",
    "                prey_transition_matrix[inode, jnode] = prob_each_neighbor\n",
    "        \n",
    "        return prey_transition_matrix\n",
    "\n",
    "\n",
    "def update_dist_pred_trans_matrix(agent_pos, graph: Graph) -> None:\n",
    "        \"\"\"\n",
    "        Updates predator transition matrix P(i, j) = Probability of predator at node i at (t + 1) given predator was at node j at (t) i.e. [j -> i]\n",
    "        (for a distracted predator)\n",
    "        \"\"\"\n",
    "        graph_nodes = graph.node_list()\n",
    "\n",
    "        pred_transition_matrix = np.zeros((len(graph_nodes), len(graph_nodes)))\n",
    "\n",
    "        for jnode in graph_nodes:\n",
    "            min_path_length = graph.shortest_path_length(jnode, agent_pos)\n",
    "            likely_nodes_plan = []\n",
    "            likely_nodes_random = graph.neighbors(jnode)\n",
    "\n",
    "            for neighbor in graph.neighbors(jnode):\n",
    "                \n",
    "                path_length = graph.shortest_path_length(neighbor, agent_pos)\n",
    "                \n",
    "                \n",
    "                if path_length <= min_path_length:\n",
    "                    if path_length < min_path_length:\n",
    "                        min_path_length = path_length\n",
    "                        likely_nodes_plan = [neighbor]\n",
    "                    else:\n",
    "                        likely_nodes_plan.append(neighbor)\n",
    "\n",
    "            for inode in likely_nodes_random:\n",
    "                # When predator moves to a 'good' node (whether it is because of focus or distraction) \n",
    "                if inode in likely_nodes_plan:\n",
    "                    pred_transition_matrix[inode, jnode] = 0.6 / len(likely_nodes_plan) + 0.4 / len(likely_nodes_random)\n",
    "                else: # when predator is distracted and goes to a 'bad' node\n",
    "                    pred_transition_matrix[inode, jnode] = 0.4 / len(likely_nodes_random)\n",
    "        \n",
    "        return  pred_transition_matrix\n",
    "\"\"\"\n",
    "This function estimates the initial utility of the state \n",
    "Good guess for estimating the utility of a state is the distance between the agent and the prey\n",
    "\"\"\"\n",
    "\n",
    "def create_all_states(total_vertices)-> list:\n",
    "\n",
    "    all_states = []  \n",
    "    # state_utility = {}\n",
    "    # state_policy = {}\n",
    "    for agent in range(total_vertices):\n",
    "        for prey_p in range(total_vertices):\n",
    "                for predator_p in range(total_vertices):\n",
    "                    current_state = (agent,prey_p,predator_p)\n",
    "                    all_states.append(current_state)\n",
    "    return all_states\n",
    "\n",
    "# initial guess\n",
    "\n",
    "def create_initial_state_utility(graph: Graph, all_states)-> dict:\n",
    "\n",
    "    state_utility = {}\n",
    "    for s in all_states:\n",
    "        # Shortest Distance from Agent to prey\n",
    "        agent_to_prey = graph.shortest_path_length(s[0] , s[1])\n",
    "\n",
    "        # Shortest Distance from Agent to Predator\n",
    "        agent_to_predator = graph.shortest_path_length(s[0] , s[2])\n",
    "\n",
    "        if s[0] == s[2]:\n",
    "            state_utility[s] = 500000000\n",
    "            \n",
    "        elif s[0] == s[1]:\n",
    "            state_utility[s] = 0\n",
    "        \n",
    "        elif agent_to_prey == 1 and s[0] != s[2]:\n",
    "            state_utility[s] = 0       \n",
    "\n",
    "        elif agent_to_predator == 1:\n",
    "            state_utility[s] = 5000000\n",
    "\n",
    "        else:\n",
    "            state_utility[s] = agent_to_prey\n",
    "\n",
    "    return state_utility\n",
    "\n",
    "\n",
    "def create_initial_state_policy(graph: Graph,all_states)-> dict:\n",
    "\n",
    "    \n",
    "    state_policy = {}\n",
    "    for s in all_states:\n",
    "        # Shortest Distance from Agent to prey\n",
    "        agent_to_prey = graph.shortest_path_length(s[0] , s[1])\n",
    "\n",
    "        # Shortest Distance from Agent to Predator\n",
    "        agent_to_predator = graph.shortest_path_length(s[0] , s[2])\n",
    "\n",
    "        if s[0] == s[1] or s[0] == s[2]:\n",
    "            state_policy[s] = s[0]\n",
    "            \n",
    "\n",
    "        elif agent_to_prey == 1 and s[0] != s[2]:\n",
    "            state_policy[s] = s[1]\n",
    "            \n",
    "\n",
    "        elif agent_to_predator == 1:\n",
    "\n",
    "            agent_neighbours = graph.neighbors(s[0])\n",
    "            dis_to_pred = {}\n",
    "            for i in agent_neighbours:\n",
    "                dis_to_pred[i] = graph.shortest_path_length(i , s[2])\n",
    "\n",
    "            max_val = max(dis_to_pred.values())\n",
    "            best_neighbors = [neighbor for neighbor, dist in dis_to_pred.items() if dist == max_val]      \n",
    "            state_policy[s] = random.choice(best_neighbors) \n",
    "            \n",
    "        else:\n",
    "            agent_neighbours = graph.neighbors(s[0])\n",
    "            state_policy[s] = random.choice(agent_neighbours) \n",
    "\n",
    "    return state_policy\n",
    "\n",
    "\n",
    "def create_actions(graph: Graph, all_states) -> dict:\n",
    "\n",
    "    return {s: graph.neighbors(s[0]) for s in all_states }\n",
    "\n",
    "\n",
    "def create_rewards(all_states)-> dict:\n",
    "    rewards = {}\n",
    "    for s in all_states:\n",
    "        if s[0] == s[1] or s[0] == s[2]:\n",
    "            rewards[s] = 0\n",
    "        else:\n",
    "            rewards[s] = 1\n",
    "\n",
    "    return rewards\n",
    "\n",
    "\n",
    "\n",
    "def create_transisition_model(graph: Graph, all_states, actions, prey_transition_matrix)-> dict:\n",
    "\n",
    "    \"\"\"Transition model From a state and an action, return a list\n",
    "        of (probability, next_state) pairs.\"\"\"\n",
    "\n",
    "    transition_model = {}\n",
    "\n",
    "    count = 0\n",
    "    for s in all_states:\n",
    "        transition_model[s] = {}\n",
    "\n",
    "        if count%2500 == 0:\n",
    "            print(count)\n",
    "        \n",
    "        count += 1\n",
    "        for a in actions[s]:\n",
    "            pred_transition_matrix = update_dist_pred_trans_matrix(a, graph)\n",
    "            transition_model[s][a] = []\n",
    "            # List of Neighbors of Prey (i.e help us determine neighbouring states of the system)\n",
    "            prey_neighbours = graph.neighbors(s[1]).copy()\n",
    "            prey_neighbours.append(s[1])\n",
    "            # List of Neighbors of Predator (i.e help us determine neighbouring states of the system)\n",
    "            predator_neighbours = graph.neighbors(s[2])\n",
    "            \n",
    "            for p in prey_neighbours:\n",
    "                for pred in predator_neighbours:\n",
    "                    next_state = (a,p,pred)\n",
    "                    transition_probability = prey_transition_matrix[p][s[1]]*pred_transition_matrix[pred][s[2]]\n",
    "                    transition_model[s][a].append((transition_probability,next_state))\n",
    "\n",
    "            # prey_neighbours.remove(s[1])\n",
    "\n",
    "    return transition_model\n",
    "\n",
    "\n",
    "\n",
    "def value_iteration(graph: Graph, all_states, actions, state_utility, state_policy, transition_model, immediate_reward, beta, error_threshold) -> dict:\n",
    "    \"\"\"  \"\"\"\n",
    "    iteration = 0\n",
    "    \n",
    "    while True:\n",
    "        print(\"Iteration no: \"+str(iteration))\n",
    "\n",
    "        old_state_utility = state_utility.copy()\n",
    "\n",
    "        error = 0\n",
    "        # count = 0\n",
    "\n",
    "        for s in all_states:\n",
    "            \n",
    "            # if count%2500==0:\n",
    "            #     print(count)\n",
    "        \n",
    "            # count+=1\n",
    "\n",
    "            # Shortest Distance from Agent to prey\n",
    "            agent_to_prey = graph.shortest_path_length(s[0] , s[1])\n",
    "\n",
    "            # Shortest Distance from Agent to Predator\n",
    "            agent_to_predator = graph.shortest_path_length(s[0] , s[2])\n",
    "\n",
    "            # What states s are easy to determine Uâˆ— for?\n",
    "              \n",
    "            if s[0] == s[1] or s[0] == s[2]: # 1. The terminal states\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            elif agent_to_prey == 1 and s[0] != s[2] : # 2. When we are lucky enough to start next to the prey \n",
    "                continue\n",
    "\n",
    "            elif agent_to_predator == 1:\n",
    "                continue\n",
    "\n",
    "            else: # UPDATE utility\n",
    "            \n",
    "            \n",
    "                # print(\"Utility of current state {} BEFORE update: {}\".format(s,old_state_utility[s]))\n",
    "                \n",
    "                expected_utility = {}\n",
    "\n",
    "                for a in actions[s]:\n",
    "                    expected_future_utility = 0\n",
    "                    for (p, s1) in transition_model[s][a]:\n",
    "                        expected_future_utility += p * state_utility[s1]\n",
    "                    expected_utility[a] = expected_future_utility\n",
    "\n",
    "                # Set Minimum reward value out of all the actions as the utility of the current state\n",
    "                min_val = min(expected_utility.values())\n",
    "\n",
    "                # UPDATE utility\n",
    "                state_utility[s] = immediate_reward[s] + beta * min_val\n",
    "\n",
    "                \n",
    "\n",
    "                \n",
    "                # print(\"Utility of current state {} AFTER update: {}\".format(s,state_utility[s]))\n",
    "\n",
    "                # Update policy \n",
    "\n",
    "                lowest_utility_neighbors = [action for action, utility in expected_utility.items() if utility == min_val]      \n",
    "\n",
    "                # Breaking ties at random\n",
    "                next_pos = random.choice(lowest_utility_neighbors)\n",
    "\n",
    "                state_policy[s] = next_pos\n",
    "\n",
    "                \n",
    "                error = max(error, abs(state_utility[s] - old_state_utility[s]))\n",
    "                \n",
    "\n",
    "        iteration +=1\n",
    "        print(\"Error:  \"+str(error))\n",
    "        \n",
    "        if error <= error_threshold :\n",
    "            return state_utility\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vertices = 50\n",
    "all_states = create_all_states(total_vertices)\n",
    "state_utility = create_initial_state_utility(G,all_states)\n",
    "state_policy = create_initial_state_policy(G,all_states)\n",
    "actions = create_actions(G,all_states)\n",
    "immediate_reward = create_rewards(all_states)\n",
    "\n",
    "prey_transition_matrix = update_prey_trans_matrix(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERATE TRANSITION MODEL FOR THE GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2500\n",
      "5000\n",
      "7500\n",
      "10000\n",
      "12500\n",
      "15000\n",
      "17500\n",
      "20000\n",
      "22500\n",
      "25000\n",
      "27500\n",
      "30000\n",
      "32500\n",
      "35000\n",
      "37500\n",
      "40000\n",
      "42500\n",
      "45000\n",
      "47500\n",
      "50000\n",
      "52500\n",
      "55000\n",
      "57500\n",
      "60000\n",
      "62500\n",
      "65000\n",
      "67500\n",
      "70000\n",
      "72500\n",
      "75000\n",
      "77500\n",
      "80000\n",
      "82500\n",
      "85000\n",
      "87500\n",
      "90000\n",
      "92500\n",
      "95000\n",
      "97500\n",
      "100000\n",
      "102500\n",
      "105000\n",
      "107500\n",
      "110000\n",
      "112500\n",
      "115000\n",
      "117500\n",
      "120000\n",
      "122500\n"
     ]
    }
   ],
   "source": [
    "# transition_model = create_transisition_model(G,all_states,actions,prey_transition_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STORE the TRANSITION MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = \"./Graphs/graph\" + str(graph_number)  + '/Transition_Model.pkl'\n",
    "# with open(file_name, 'wb') as f:\n",
    "#     loaded_dict = pickle.dump(transition_model,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READ THE TRANSITION MODEL FOR THE PARTICULAR GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./Graphs/graph\" + str(graph_number)  + '/Transition_Model.pkl'\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    transition_model = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERATE OPTIMAL STATE UTILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration no: 0\n",
      "Error:  366666666.1333332\n",
      "Iteration no: 1\n",
      "Error:  2688886.6066089254\n",
      "Iteration no: 2\n",
      "Error:  780320.9560309784\n",
      "Iteration no: 3\n",
      "Error:  104937.84613369487\n",
      "Iteration no: 4\n",
      "Error:  90842.35431295598\n",
      "Iteration no: 5\n",
      "Error:  33099.86212387045\n",
      "Iteration no: 6\n",
      "Error:  6521.225305882741\n",
      "Iteration no: 7\n",
      "Error:  1391.1964013105753\n",
      "Iteration no: 8\n",
      "Error:  296.7836131723161\n",
      "Iteration no: 9\n",
      "Error:  63.321091559562774\n",
      "Iteration no: 10\n",
      "Error:  13.655186942480213\n",
      "Iteration no: 11\n",
      "Error:  3.147094180654676\n",
      "Iteration no: 12\n",
      "Error:  1.1170657082361473\n",
      "Iteration no: 13\n",
      "Error:  0.868680189604337\n",
      "Iteration no: 14\n",
      "Error:  0.7136960727778856\n",
      "Iteration no: 15\n",
      "Error:  0.5180259426687854\n",
      "Iteration no: 16\n",
      "Error:  0.4190514636805531\n",
      "Iteration no: 17\n",
      "Error:  0.3651519808924846\n",
      "Iteration no: 18\n",
      "Error:  0.3231767330809987\n",
      "Iteration no: 19\n",
      "Error:  0.28632850937319887\n",
      "Iteration no: 20\n",
      "Error:  0.2480682661076301\n",
      "Iteration no: 21\n",
      "Error:  0.21842508588050435\n",
      "Iteration no: 22\n",
      "Error:  0.1916566665210233\n",
      "Iteration no: 23\n",
      "Error:  0.16846895474871104\n",
      "Iteration no: 24\n",
      "Error:  0.14605813806710444\n",
      "Iteration no: 25\n",
      "Error:  0.12896472149892446\n",
      "Iteration no: 26\n",
      "Error:  0.11067490060041152\n",
      "Iteration no: 27\n",
      "Error:  0.09236561264570042\n",
      "Iteration no: 28\n",
      "Error:  0.07582424417697808\n",
      "Iteration no: 29\n",
      "Error:  0.06140959941923896\n",
      "Iteration no: 30\n",
      "Error:  0.0488547670999715\n",
      "Iteration no: 31\n",
      "Error:  0.038508013804118946\n",
      "Iteration no: 32\n",
      "Error:  0.030357514389077522\n",
      "Iteration no: 33\n",
      "Error:  0.024438890929289414\n",
      "Iteration no: 34\n",
      "Error:  0.019359289962117998\n",
      "Iteration no: 35\n",
      "Error:  0.015316692478108962\n",
      "Iteration no: 36\n",
      "Error:  0.012082770993696812\n",
      "Iteration no: 37\n",
      "Error:  0.009494918842847255\n",
      "Iteration no: 38\n",
      "Error:  0.007430587171899816\n",
      "Iteration no: 39\n",
      "Error:  0.005782064161582667\n",
      "Iteration no: 40\n",
      "Error:  0.004502599718382072\n",
      "Iteration no: 41\n",
      "Error:  0.0034956403893673382\n",
      "Iteration no: 42\n",
      "Error:  0.0027033248311667535\n",
      "Iteration no: 43\n",
      "Error:  0.0020861825518281307\n",
      "Iteration no: 44\n",
      "Error:  0.0016091450658777262\n",
      "Iteration no: 45\n",
      "Error:  0.0012417736025582826\n",
      "Iteration no: 46\n",
      "Error:  0.0009593630052151525\n",
      "Iteration no: 47\n",
      "Error:  0.0007467777586143143\n",
      "Iteration no: 48\n",
      "Error:  0.0005845729185693926\n",
      "Iteration no: 49\n",
      "Error:  0.0004599576747921219\n",
      "Iteration no: 50\n",
      "Error:  0.0003630905592260092\n",
      "Iteration no: 51\n",
      "Error:  0.0002876539679199652\n",
      "Iteration no: 52\n",
      "Error:  0.00022877706240365114\n",
      "Iteration no: 53\n",
      "Error:  0.00018252029521548252\n",
      "Iteration no: 54\n",
      "Error:  0.00014594006578505514\n",
      "Iteration no: 55\n",
      "Error:  0.00011690113590390183\n",
      "Iteration no: 56\n",
      "Error:  9.378520178415783e-05\n"
     ]
    }
   ],
   "source": [
    "beta = 1\n",
    "error_threshold = 0.0001\n",
    "\n",
    "optimal_state_utility = value_iteration(G, all_states, actions, state_utility, state_policy, transition_model, immediate_reward, beta, error_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STORE the Optimal State Utility for the particular graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PKL file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = \"./Graphs/graph\" + str(graph_number)  + '/Optimal_su.pkl'\n",
    "# with open(file_name, 'wb') as f:\n",
    "#     loaded_dict = pickle.dump(optimal_state_utility,f)\n",
    "\n",
    "# file_name = \"./Graphs/graph\" + str(graph_number)  + '/Optimal_policy.pkl'\n",
    "# with open(file_name, 'wb') as f:\n",
    "#     loaded_dict = pickle.dump(state_policy,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "\n",
    "# a_p = []\n",
    "# p_p = []\n",
    "# pred_p = []\n",
    "# o_p = []\n",
    "# d = []\n",
    "# o = []\n",
    "# for i in list(optimal_state_utility.keys()):\n",
    "#     a_p.append(i[0])\n",
    "#     p_p.append(i[1])\n",
    "#     pred_p.append(i[2])\n",
    "#     d.append(G.shortest_path_length(i[0],i[1])/2)\n",
    "#     o.append(G.shortest_path_length(i[0],i[2])/2)\n",
    "\n",
    "    \n",
    "    \n",
    "# df[\"Agent_position\"] = a_p\n",
    "# df[\"Prey_position\"] = p_p\n",
    "# df[\"Predator_position\"]= pred_p\n",
    "# df[\"Optimal_Policy\"] = state_policy.values()\n",
    "# df[\"Optimal_utility\"] = state_utility.values()\n",
    "# df['Dist. b/w Agent and Prey'] = d\n",
    "# df['Dist. b/w Agent and Predator'] = o\n",
    "\n",
    "# file_name = \"./Graphs/graph\" + str(graph_number)  + '/Optimal_su.csv'\n",
    "# df.to_csv(file_name, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READ the Optimal state utility for the particular graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./Graphs/graph\" + str(graph_number)  + '/Optimal_su.pkl'\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    optimal_state_utility = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READ the Optimal state policy for the particular graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./Graphs/graph\" + str(graph_number)  + '/Optimal_policy.pkl'\n",
    "with open(file_name, 'rb') as f:\n",
    "    state_policy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import probability as prob\n",
    "from graph_utils import Graph\n",
    "\n",
    "class Agent:\n",
    "    \"\"\"\n",
    "    Object that has stuff on the agent\n",
    "    \"\"\"\n",
    "    def __init__(self, name, graph: Graph,pos) -> None:\n",
    "        \"\"\"\n",
    "        Initialization\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "\n",
    "        # Spawn Agent at a random node (other than the prey and predator spawn nodes)\n",
    "        self.node = pos\n",
    "        # random.choice(graph.node_list())\n",
    "\n",
    "        total_nodes = len(graph.node_list())\n",
    "\n",
    "        # Initialize prey probability matrix to (1/49)s\n",
    "        self.prey_beliefs = []\n",
    "\n",
    "        for _ in range(total_nodes):\n",
    "            self.prey_beliefs.append(1 / (total_nodes - 1))\n",
    "\n",
    "        self.prey_beliefs[self.node] = 0.0\n",
    "\n",
    "        # Initialize predator probability matrix to 0s\n",
    "        self.pred_beliefs = []\n",
    "\n",
    "        for _ in range(total_nodes):\n",
    "            self.pred_beliefs.append(0.0)\n",
    "\n",
    "        # For partial prey\n",
    "        self.prey_transition_matrix = np.zeros((total_nodes, total_nodes), dtype=float)\n",
    "\n",
    "        # For partial predator\n",
    "        self.pred_transition_matrix = np.zeros((total_nodes, total_nodes), dtype=float)\n",
    "\n",
    "        print(\"Initial Agent Position: \" + str(self.node))\n",
    "\n",
    "    def prey_move_sim(self, graph: Graph, prey_pos, agent_future_pos) -> int:\n",
    "        \"\"\"\n",
    "        The function simulates the predator's movement pattern (used in Agents 2, 4, 6 and 8)\n",
    "        \"\"\"\n",
    "        possible_positions = [prey_pos]\n",
    "        possible_positions.extend(graph.neighbors(prey_pos))\n",
    "\n",
    "        path_lengths = {}\n",
    "\n",
    "        for prey in possible_positions:\n",
    "            path_lengths[prey] = graph.shortest_path_length(prey, agent_future_pos)\n",
    "\n",
    "        # Just set the current position to the best neighbor (and break ties randomly if there is more than one)\n",
    "        return round(sum(list(path_lengths.values())) / len(possible_positions))\n",
    "\n",
    "    def predator_move_sim(self, graph: Graph, pred_pos, agent_future_pos, distracted=False) -> int:\n",
    "        \"\"\"\n",
    "        The function simulates the predator's movement pattern (used in Agents 2, 4, 6 and 8)\n",
    "        \"\"\"\n",
    "        min_path_len = math.inf\n",
    "\n",
    "        for neighbor in graph.neighbors(pred_pos):\n",
    "            \n",
    "            path_length = graph.shortest_path_length(neighbor, agent_future_pos)\n",
    "            \n",
    "            if path_length < min_path_len:\n",
    "                min_path_len = path_length # this is done because we have a clear cut best neighbor\n",
    "\n",
    "        # Just set the current position to the best neighbor (and break ties randomly if there is more than one)\n",
    "        return path_length\n",
    "\n",
    "    def update_prey_trans_matrix(self, graph: Graph) -> None:\n",
    "        \"\"\"\n",
    "        Updates prey transition matrix P(i, j) = Probability of prey at node i at (t + 1) given prey was at node j at (t) i.e. [j -> i]\n",
    "        \"\"\"\n",
    "        graph_nodes = graph.node_list()\n",
    "\n",
    "        for jnode in graph_nodes:\n",
    "\n",
    "            neighbors = list(graph.neighbors(jnode))\n",
    "            prob_each_neighbor = 1 / (len(neighbors) + 1)\n",
    "    \n",
    "            # When prey stays at the same node\n",
    "            self.prey_transition_matrix[jnode, jnode] = prob_each_neighbor\n",
    "\n",
    "            # When prey moves to a different node\n",
    "            for inode in neighbors:\n",
    "                self.prey_transition_matrix[inode, jnode] = prob_each_neighbor\n",
    "\n",
    "    def update_pred_trans_matrix(self, graph: Graph) -> None:\n",
    "        \"\"\"\n",
    "        Updates predator transition matrix P(i, j) = Probability of predator at node i at (t + 1) given predator was at node j at (t) i.e. [j -> i]\n",
    "        (for a non-distracted predator)\n",
    "        \"\"\"\n",
    "        graph_nodes = graph.node_list()\n",
    "\n",
    "        self.pred_transition_matrix = np.zeros((len(graph_nodes), len(graph_nodes)))\n",
    "\n",
    "        for jnode in graph_nodes:\n",
    "            min_path_length = math.inf\n",
    "            likely_nodes_plan = []\n",
    "\n",
    "            for neighbor in graph.neighbors(jnode):\n",
    "                \n",
    "                path_length = graph.shortest_path_length(jnode, self.node)\n",
    "                \n",
    "                if path_length <= min_path_length:\n",
    "                    if path_length < min_path_length:\n",
    "                        min_path_length = path_length\n",
    "                    likely_nodes_plan.append(neighbor)\n",
    "\n",
    "            for inode in likely_nodes_plan:\n",
    "                self.pred_transition_matrix[inode, jnode] = 1 / len(likely_nodes_plan)\n",
    "\n",
    "\n",
    "    def update_dist_pred_trans_matrix(self, graph: Graph) -> None:\n",
    "        \"\"\"\n",
    "        Updates predator transition matrix P(i, j) = Probability of predator at node i at (t + 1) given predator was at node j at (t) i.e. [j -> i]\n",
    "        (for a distracted predator)\n",
    "        \"\"\"\n",
    "        graph_nodes = graph.node_list()\n",
    "\n",
    "        self.pred_transition_matrix = np.zeros((len(graph_nodes), len(graph_nodes)))\n",
    "\n",
    "        for jnode in graph_nodes:\n",
    "            min_path_length = math.inf\n",
    "            likely_nodes_plan = []\n",
    "            likely_nodes_random = graph.neighbors(jnode)\n",
    "\n",
    "            for neighbor in graph.neighbors(jnode):\n",
    "                \n",
    "                path_length = graph.shortest_path_length(jnode, self.node)\n",
    "                \n",
    "                if path_length <= min_path_length:\n",
    "                    if path_length < min_path_length:\n",
    "                        min_path_length = path_length\n",
    "                        likely_nodes_plan = [neighbor]\n",
    "                    else:\n",
    "                        likely_nodes_plan.append(neighbor)\n",
    "\n",
    "            for inode in likely_nodes_random:\n",
    "                # When predator moves to a 'good' node (whether it is because of focus or distraction) \n",
    "                if inode in likely_nodes_plan:\n",
    "                    self.pred_transition_matrix[inode, jnode] = 0.6 / len(likely_nodes_plan) + 0.4 / len(likely_nodes_random)\n",
    "                else: # when predator is distracted and goes to a 'bad' node\n",
    "                    self.pred_transition_matrix[inode, jnode] = 0.4 / len(likely_nodes_random)\n",
    "\n",
    "    def move_1(self, graph: Graph, prey_pos, pred_pos) -> None:\n",
    "        \"\"\"\n",
    "        This function moves the agent 1 according to the strategy mentioned in the write up\n",
    "        \"\"\"\n",
    "        \n",
    "        # Shortest Distance from Agent to prey\n",
    "        agent_to_prey = graph.shortest_path_length(self.node , prey_pos)\n",
    "        \n",
    "        # Shortest Distance from Agent to Predator\n",
    "        agent_to_predator = graph.shortest_path_length(self.node , pred_pos)\n",
    "\n",
    "        # List of Neighbors of Agent\n",
    "        agent_neighbours = graph.neighbors(self.node)\n",
    "\n",
    "        # Distance of shortest path from each neighbour to prey and predator\n",
    "        dist_neighbors = {}\n",
    "        \n",
    "        # Setting priority for every neighbor according to the order followed by Agent1 \n",
    "        priority = {}\n",
    "\n",
    "        for neighbor in agent_neighbours:\n",
    "\n",
    "            # Distance of shortest path from neighbor to prey\n",
    "            neighbor_to_prey = graph.shortest_path_length( neighbor, prey_pos)\n",
    "\n",
    "            # Distance of shortest path from neighbor to predator\n",
    "            neighbor_to_predator = graph.shortest_path_length( neighbor, pred_pos)\n",
    "\n",
    "            dist_neighbors[neighbor] = (neighbor_to_prey,neighbor_to_predator)\n",
    "\n",
    "            if neighbor_to_prey < agent_to_prey and neighbor_to_predator > agent_to_predator:\n",
    "                priority[neighbor] = 1\n",
    "                \n",
    "            elif neighbor_to_prey < agent_to_prey and neighbor_to_predator == agent_to_predator :\n",
    "                priority[neighbor] = 2\n",
    "                \n",
    "            elif neighbor_to_prey == agent_to_prey and neighbor_to_predator > agent_to_predator :\n",
    "                priority[neighbor] = 3\n",
    "                \n",
    "            elif neighbor_to_prey == agent_to_prey and neighbor_to_predator == agent_to_predator :\n",
    "                priority[neighbor] = 4\n",
    "                \n",
    "            elif neighbor_to_predator > agent_to_predator :\n",
    "                priority[neighbor] = 5\n",
    "                \n",
    "            elif neighbor_to_predator == agent_to_predator :\n",
    "                priority[neighbor] = 6\n",
    "                \n",
    "            else :\n",
    "                priority[neighbor] = 7\n",
    "        \n",
    "        # Highest priority value out of all the neighbors\n",
    "        min_val = min(priority.values())\n",
    "\n",
    "        # Neighbors with the Highest priority\n",
    "        if min_val < 7:\n",
    "            # List of neighbors with highest priority\n",
    "            Highest_priority_neighbors = [key for key, value in priority.items() if value == min_val]      \n",
    "\n",
    "            # Breaking ties at random\n",
    "            next_pos = random.choice(Highest_priority_neighbors)\n",
    "            \n",
    "            # Update node for the agent\n",
    "            self.node = next_pos\n",
    "\n",
    "        else:\n",
    "            self.node = self.node\n",
    "    \n",
    "    def move_2(self, graph: Graph, prey_pos, pred_pos, distracted=False) -> None:\n",
    "        \"\"\"\n",
    "        Movement logic for Agent 2\n",
    "        \"\"\"\n",
    "        # Shortest Distance from Agent to prey\n",
    "        agent_to_prey = graph.shortest_path_length(self.node , prey_pos)\n",
    "        \n",
    "        # Shortest Distance from Agent to Predator\n",
    "        agent_to_predator = graph.shortest_path_length(self.node , pred_pos)\n",
    "\n",
    "        # List of Neighbors of Agent\n",
    "        agent_neighbours = graph.neighbors(self.node)\n",
    "\n",
    "        # Distance of shortest path from each neighbour to prey and predator\n",
    "        dist_neighbors = {}\n",
    "\n",
    "        # Setting priority for every neighbor according to the order followed by Agent1 \n",
    "        priority = {}\n",
    "\n",
    "        for neighbor in agent_neighbours:\n",
    "            # Distance of shortest path from neighbor to prey\n",
    "            neighbor_to_prey = graph.shortest_path_length(neighbor, prey_pos)\n",
    "\n",
    "            # Distance of shortest path from neighbor to predator\n",
    "            neighbor_to_predator = graph.shortest_path_length( neighbor, pred_pos)\n",
    "\n",
    "            # Distance of shortest path from neighbor to predator future\n",
    "            neighbor_to_predator_future = self.predator_move_sim(graph, pred_pos, neighbor, distracted) # We just need distance\n",
    "\n",
    "            neighbor_to_prey_future = self.prey_move_sim(graph, prey_pos, neighbor) # We get an average distance\n",
    "\n",
    "            dist_neighbors[neighbor] = (neighbor_to_prey, neighbor_to_predator)\n",
    "\n",
    "            if neighbor_to_prey_future < agent_to_prey and neighbor_to_predator_future > agent_to_predator and neighbor_to_predator >= agent_to_predator :\n",
    "                priority[neighbor] = 1\n",
    "\n",
    "            elif neighbor_to_prey_future < agent_to_prey and neighbor_to_predator_future == agent_to_predator and neighbor_to_predator >= agent_to_predator :\n",
    "                priority[neighbor] = 2\n",
    "                \n",
    "            elif neighbor_to_prey_future == agent_to_prey and neighbor_to_predator_future > agent_to_predator and neighbor_to_predator >= agent_to_predator :\n",
    "                priority[neighbor] = 3\n",
    "            \n",
    "            elif neighbor_to_prey_future == agent_to_prey and neighbor_to_predator_future == agent_to_predator and neighbor_to_predator >= agent_to_predator :\n",
    "                priority[neighbor] = 4\n",
    "\n",
    "            elif neighbor_to_prey < agent_to_prey and neighbor_to_predator_future > agent_to_predator and neighbor_to_predator >= agent_to_predator :\n",
    "                priority[neighbor] = 5\n",
    "\n",
    "            elif neighbor_to_prey < agent_to_prey and neighbor_to_predator_future == agent_to_predator and neighbor_to_predator >= agent_to_predator :\n",
    "                priority[neighbor] = 6\n",
    "                \n",
    "            elif neighbor_to_prey == agent_to_prey and neighbor_to_predator_future > agent_to_predator and neighbor_to_predator >= agent_to_predator :\n",
    "                priority[neighbor] = 7\n",
    "            \n",
    "            elif neighbor_to_prey == agent_to_prey and neighbor_to_predator_future == agent_to_predator and neighbor_to_predator >= agent_to_predator :\n",
    "                priority[neighbor] = 8\n",
    "\n",
    "            elif neighbor_to_predator_future > agent_to_predator and neighbor_to_predator >= agent_to_predator :\n",
    "                priority[neighbor] = 9\n",
    "\n",
    "            elif neighbor_to_predator_future == agent_to_predator and neighbor_to_predator >= agent_to_predator :\n",
    "                priority[neighbor] = 10\n",
    "\n",
    "            elif neighbor_to_prey_future < agent_to_prey and neighbor_to_predator > agent_to_predator:\n",
    "                priority[neighbor] = 11\n",
    "                \n",
    "            elif neighbor_to_prey_future < agent_to_prey and neighbor_to_predator == agent_to_predator :\n",
    "                priority[neighbor] = 12\n",
    "\n",
    "            elif neighbor_to_prey_future == agent_to_prey and neighbor_to_predator > agent_to_predator :\n",
    "                priority[neighbor] = 13\n",
    "                \n",
    "            elif neighbor_to_prey_future == agent_to_prey and neighbor_to_predator == agent_to_predator :\n",
    "                priority[neighbor] = 14\n",
    "\n",
    "            elif neighbor_to_prey < agent_to_prey and neighbor_to_predator > agent_to_predator :\n",
    "                priority[neighbor] = 15\n",
    "                \n",
    "            elif neighbor_to_prey < agent_to_prey and neighbor_to_predator == agent_to_predator :\n",
    "                priority[neighbor] = 16\n",
    "\n",
    "            elif neighbor_to_prey == agent_to_prey and neighbor_to_predator > agent_to_predator :\n",
    "                priority[neighbor] = 17\n",
    "                \n",
    "            elif neighbor_to_prey == agent_to_prey and neighbor_to_predator == agent_to_predator :\n",
    "                priority[neighbor] = 18\n",
    "\n",
    "            elif neighbor_to_predator > agent_to_predator :\n",
    "                priority[neighbor] = 19\n",
    "                \n",
    "            elif neighbor_to_predator == agent_to_predator :\n",
    "                priority[neighbor] = 20\n",
    "\n",
    "            else :\n",
    "                priority[neighbor] = 21\n",
    "            \n",
    "        # Highest priority value out of all the neighbors\n",
    "        min_val = 21\n",
    "        min_val = min(priority.values())\n",
    "\n",
    "        # Neighbors with the Highest priority\n",
    "        if min_val < 21:\n",
    "            # List of neighbors with highest priority\n",
    "            Highest_priority_neighbors = [key for key, value in priority.items() if value == min_val]\n",
    "\n",
    "            # Breaking ties at random\n",
    "            next_pos = random.choice(Highest_priority_neighbors)\n",
    "\n",
    "            # Update node for the agent\n",
    "            self.node = next_pos\n",
    "        \n",
    "        else:\n",
    "            self.node = self.node\n",
    "\n",
    "    def move_3(self, graph: Graph, prey_pos: int, pred_pos: int, time_steps: int) -> bool:\n",
    "        \"\"\"\n",
    "        Movement logic for Agents 3 and 4\n",
    "        \"\"\"\n",
    "        error = 10 ** -5\n",
    "\n",
    "        if time_steps == 1:\n",
    "            # Initial transition matrix (not to be altered)\n",
    "            self.update_prey_trans_matrix(graph)\n",
    "\n",
    "        elif time_steps > 1:\n",
    "            # Update beliefs post prey move\n",
    "            \"\"\"\n",
    "            P ( prey at some_node now ) = SUM [ P ( prey at some_node now AND prey was at old_node then ) ]\n",
    "                ... Marginalization\n",
    "\n",
    "            P ( prey at some_node now ) = SUM [ P ( prey at old_node then ) * P ( prey at some_node now | prey at old_node then ) ]\n",
    "                ... Conditional Factoring\n",
    "\n",
    "            P ( prey at some_node now ) = SUM [ P ( prey at old_node then ) * P ( some_node | old_node ) ]\n",
    "                ... Simplifying the last probability which is basically the transition probability\n",
    "            \n",
    "            New beilief = DOT PRODUCT [ old_belief , row in the transition matrix ]\n",
    "                ... In terms of what we have\n",
    "            \"\"\"\n",
    "\n",
    "            updated_beliefs_ndarray = np.matmul(self.prey_transition_matrix, np.array(self.prey_beliefs))\n",
    "            self.prey_beliefs = updated_beliefs_ndarray.tolist()\n",
    "\n",
    "            if not prob.check_sum_beliefs(self.prey_beliefs):\n",
    "                raise ValueError(\"Sum of beliefs error (after prey move update)\")\n",
    "\n",
    "        # Find the best survey pos\n",
    "        best_survey_node = prob.node_to_survey(self.prey_beliefs, \"prey\")\n",
    "\n",
    "        # Perform survey on the best node\n",
    "        self.prey_beliefs = prob.survey(self.prey_beliefs, best_survey_node, prey_pos)\n",
    "\n",
    "        if not prob.check_sum_beliefs(self.prey_beliefs):\n",
    "            raise ValueError(\"Sum of beliefs error (after node survey)\")\n",
    "\n",
    "        # Find the node for which we have highest belief\n",
    "        max_prob_nodes = [node for node, belief in enumerate(self.prey_beliefs) if belief == max(self.prey_beliefs)]\n",
    "\n",
    "        # If more than one, break ties randomly if \n",
    "        prob_prey_pos = random.choice(max_prob_nodes)\n",
    "\n",
    "        print(\"Highest probable current position of prey is [{}] with probability [{}], so we'll use that info\".format(prob_prey_pos, self.prey_beliefs[prob_prey_pos]))\n",
    "\n",
    "        if self.name == \"agent3\":\n",
    "            # Do the actual movement to highest belief node based on agent 1 logic for agent 3\n",
    "            self.move_1(graph, prob_prey_pos, pred_pos)\n",
    "        \n",
    "        elif self.name == \"agent4\":\n",
    "            # Do the actual movement to highest belief node based on agent 2 logic for agent 4\n",
    "            self.move_2(graph, prob_prey_pos, pred_pos)\n",
    "\n",
    "        # Update beliefs post agent move\n",
    "        prob.survey(self.prey_beliefs, self.node, prey_pos)\n",
    "\n",
    "        if not prob.check_sum_beliefs(self.prey_beliefs):\n",
    "            raise ValueError(\"Sum of beliefs error (after agent move)\")\n",
    "        \n",
    "        if 1.0 - error <= max(self.prey_beliefs) <= 1.0 + error:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def move_utility(self, graph: Graph, prey_pos, pred_pos,state_policy) -> None:\n",
    "        \"\"\"\n",
    "        This function moves the agent according to the U* strategy mentioned in the write up\n",
    "        \"\"\"\n",
    "\n",
    "        state = (self.node,prey_pos,pred_pos)        \n",
    "        self.node = state_policy[state] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non Terminal States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4950\n",
      "120050\n",
      "125000\n"
     ]
    }
   ],
   "source": [
    "terminal_states = []\n",
    "non_terminal_states = []\n",
    "for s in all_states:\n",
    "    if s[0] == s[1] or s[0] == s[2]:\n",
    "        terminal_states.append(s)\n",
    "    else:\n",
    "        non_terminal_states.append(s)\n",
    "print(len(terminal_states))\n",
    "print(len(non_terminal_states))\n",
    "print(len(non_terminal_states) + len(terminal_states))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Number: 11\n"
     ]
    }
   ],
   "source": [
    "total_vertices = 50\n",
    "agentNum = 11\n",
    "max_steps = 5000\n",
    "num_runs = 1000\n",
    "num_trials = 30\n",
    "print(\"Agent Number: \"+str(agentNum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose N random states from non terminal states\n",
    "\n",
    "# selected_idx = random.sample(range(0, len(non_terminal_states)), num_runs)\n",
    "\n",
    "# selected_states = [ non_terminal_states[i] for i in selected_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STORE THE SELECTED STATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = \"./Graphs/graph\" + str(graph_number) + \"/agent_csv\" + \"/starting_states.pkl\"\n",
    "# with open(file_name, 'wb') as f:\n",
    "#     loaded_dict = pickle.dump(selected_states,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STORE CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "\n",
    "# a_p = []\n",
    "# p_p = []\n",
    "# pred_p = []\n",
    "# o_p = []\n",
    "\n",
    "# for i in selected_states :\n",
    "#     a_p.append(i[0])\n",
    "#     p_p.append(i[1])\n",
    "#     pred_p.append(i[2])\n",
    "\n",
    "    \n",
    "    \n",
    "# df[\"Agent_position\"] = a_p\n",
    "# df[\"Prey_position\"] = p_p\n",
    "# df[\"Predator_position\"]= pred_p\n",
    "\n",
    "\n",
    "# file_name = \"./Graphs/graph\" + str(graph_number) + \"/agent_csv\" + \"/starting_states.csv\"\n",
    "# df.to_csv(file_name, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the selected states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./Graphs/graph\" + str(graph_number) + \"/agent_csv\" + \"/starting_states.pkl\"\n",
    "with open(file_name, 'rb') as f:\n",
    "    selected_states = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run number: 1000\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 32\n",
      "Total timesteps: 5\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 39\n",
      "Total timesteps: 32\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 49\n",
      "Total timesteps: 16\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 32\n",
      "Total timesteps: 30\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 35\n",
      "Total timesteps: 23\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 33\n",
      "Total timesteps: 11\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 37\n",
      "Total timesteps: 24\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 36\n",
      "Total timesteps: 12\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 39\n",
      "Total timesteps: 9\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 41\n",
      "Total timesteps: 23\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 37\n",
      "Total timesteps: 16\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 31\n",
      "Total timesteps: 4\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 32\n",
      "Total timesteps: 5\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 32\n",
      "Total timesteps: 7\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 40\n",
      "Total timesteps: 12\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 33\n",
      "Total timesteps: 25\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 32\n",
      "Total timesteps: 5\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 41\n",
      "Total timesteps: 54\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 4\n",
      "Total timesteps: 13\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 32\n",
      "Total timesteps: 5\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 41\n",
      "Total timesteps: 22\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 31\n",
      "Total timesteps: 20\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 31\n",
      "Total timesteps: 17\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 44\n",
      "Total timesteps: 23\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 48\n",
      "Total timesteps: 18\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 33\n",
      "Total timesteps: 12\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 42\n",
      "Total timesteps: 43\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 32\n",
      "Total timesteps: 5\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 42\n",
      "Total timesteps: 20\n",
      "\n",
      "Initial Agent Position: 29\n",
      "Agent Caught the Prey at location: 31\n",
      "Total timesteps: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from graph_utils import Graph\n",
    "# from agent import Agent\n",
    "from predator import Predator\n",
    "from prey import Prey\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# total_vertices = int(input(\"Enter the total vertices number: \"))\n",
    "# agentNum = int(input(\"Enter the agent number: \"))\n",
    "\n",
    "agentChar = \"\"\n",
    "if agentNum == 7 or agentNum == 8:\n",
    "    agentChar = str(input(\"Enter a space if normal agent 7 or 8, else enter b: \")).strip()\n",
    "\n",
    "# num_runs = int(input(\"Enter the number of runs: \"))\n",
    "# num_trials = int(input(\"Enter the number of trials per run: \"))\n",
    "# max_steps = int(input(\"Enter the max number of steps each trial should run for: \"))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "total_success = 0\n",
    "\n",
    "\n",
    "\n",
    "# Run the agent/prey/predator game (based on input params)\n",
    "for run in range(num_runs):\n",
    "\n",
    "    print(\"Run number: \"+ str(run))\n",
    "    print()\n",
    "    success = {}\n",
    "    fail_predator = {}\n",
    "    fail_hang = {}\n",
    "\n",
    "    time_steps = {}\n",
    "    times_prey_known = {}\n",
    "    times_pred_known = {}\n",
    "\n",
    "    agent_path = {}\n",
    "    prey_path = {}\n",
    "    predator_path = {}\n",
    "\n",
    "    current_state = selected_states[run]\n",
    "    \n",
    "\n",
    "    for trial in range(num_trials):\n",
    "        success[trial] = fail_predator[trial] = fail_hang[trial] = 0\n",
    "\n",
    "    for trial in range(num_trials):\n",
    "\n",
    "        # print(\"Trial number: \"+ str(trial))\n",
    "        # print()\n",
    "\n",
    "        agent_path[trial] = []\n",
    "        prey_path[trial] = []\n",
    "        predator_path[trial] = []\n",
    "\n",
    "        # Spawn the agent\n",
    "        a = Agent(\"agent\" + str(agentNum) + agentChar, G, current_state[0])\n",
    "        agent_path[trial].append(a.node)\n",
    "\n",
    "        # Spawn Prey and Predator\n",
    "        prey = Prey(G, a,current_state[1])\n",
    "        prey_path[trial].append(prey.pos)\n",
    "\n",
    "        predator = Predator(G, a,current_state[2])\n",
    "        predator_path[trial].append(predator.pos)\n",
    "\n",
    "        # print(\"Initial Prey Position: \"+str(prey.pos))\n",
    "        # print(\"Initial Predator Position: \"+str(predator.pos))\n",
    "\n",
    "        # print(\"Initial Distance between Agent and Prey: \"+str(G.shortest_path_length(a.node,prey.pos)))\n",
    "        # print(\"Initial Distance between Agent and Predator: \"+str(G.shortest_path_length(a.node,predator.pos)))\n",
    "        # print()\n",
    "        # By default set the agent as not caught\n",
    "        caught_us = False\n",
    "        caught_prey = False\n",
    "\n",
    "        # Resetting time_steps - an upper bound of max_steps is used to make sure agent isn't running forever\n",
    "        time_steps[trial] = 0\n",
    "        times_prey_known[trial] = 0\n",
    "        times_pred_known[trial] = 0\n",
    "\n",
    "        while not caught_us and not caught_prey and time_steps[trial] < max_steps:\n",
    "\n",
    "            time_steps[trial] += 1\n",
    "\n",
    "            # MOVE AGENT\n",
    "            if a.name == \"agent1\":\n",
    "                a.move_1(G, prey.pos, predator.pos)\n",
    "                agent_path[trial].append(a.node)\n",
    "                times_pred_known[trial] += 1\n",
    "                times_prey_known[trial] += 1\n",
    "                # print(\"Next position of Agent: \" + str(a.node))\n",
    "\n",
    "\n",
    "            elif a.name == \"agent2\":\n",
    "                a.move_2(G, prey.pos, predator.pos, distracted=False)\n",
    "                agent_path[trial].append(a.node)\n",
    "                times_pred_known[trial] += 1\n",
    "                times_prey_known[trial] += 1\n",
    "                # print(\"Next position of Agent: \" + str(a.node))\n",
    "\n",
    "            elif a.name == \"agent3\":\n",
    "                if a.move_3(G, prey.pos, predator.pos, time_steps[trial]):\n",
    "                    agent_path[trial].append(a.node)\n",
    "                    times_prey_known[trial] += 1\n",
    "                times_pred_known[trial] += 1\n",
    "                # print(\"Next position of Agent: \" + str(a.node))\n",
    "\n",
    "            elif a.name == \"agent4\":\n",
    "                if a.move_3(G, prey.pos, predator.pos, time_steps[trial]):\n",
    "                    agent_path[trial].append(a.node)\n",
    "                    times_prey_known[trial] += 1\n",
    "                times_pred_known[trial] += 1\n",
    "                # print(\"Next position of Agent: \" + str(a.node))\n",
    "            \n",
    "            if a.name == \"agent11\":\n",
    "                a.move_utility(G, prey.pos, predator.pos, state_policy)\n",
    "                agent_path[trial].append(a.node)\n",
    "                times_pred_known[trial] += 1\n",
    "                times_prey_known[trial] += 1\n",
    "                # print(\"Next position of Agent: \" + str(a.node))\n",
    "                # print(\"AGENT_to_Prey BEFORE prey move: \"+str(G.shortest_path_length(a.node,prey.pos)))\n",
    "\n",
    "            \n",
    "\n",
    "            # CHECK IF CAUGHT OR NOT\n",
    "            if a.node == predator.pos :\n",
    "                caught_us = True\n",
    "                fail_predator[trial] = 1\n",
    "                break\n",
    "\n",
    "            elif a.node == prey.pos :\n",
    "                caught_prey = True\n",
    "                success[trial] = 1\n",
    "                break           \n",
    "\n",
    "            # MOVE PREY (Randomly)\n",
    "            prey.move_prey(G)\n",
    "            prey_path[trial].append(prey.pos)\n",
    "            # print(\"Next position of Prey: \" + str(prey.pos))\n",
    "            \n",
    "            # print(\"AGENT_to_Prey AFTER prey move: \"+str(G.shortest_path_length(a.node,prey.pos)))\n",
    "\n",
    "\n",
    "            # CHECK IF CAUGHT OR NOT\n",
    "            if a.node == predator.pos :\n",
    "                caught_us = True\n",
    "                fail_predator[trial] = 1\n",
    "                break\n",
    "\n",
    "            elif a.node == prey.pos :\n",
    "                caught_prey = True\n",
    "                success[trial] = 1\n",
    "                break\n",
    "\n",
    "            # MOVE PREDATOR (Shortest path to agent)\n",
    "            predator.move_distracted_predator(G, a)\n",
    "            predator_path[trial].append(predator.pos)\n",
    "            # print(\"Next position of Predator: \" + str(predator.pos))\n",
    "            # print()\n",
    "\n",
    "            # CHECK IF CAUGHT OR NOT\n",
    "            if a.node == predator.pos:\n",
    "                caught_us = True\n",
    "                fail_predator[trial] = 1\n",
    "                break\n",
    "\n",
    "            elif a.node == prey.pos:\n",
    "                caught_prey = True\n",
    "                success[trial] = 1\n",
    "                break\n",
    "        \n",
    "        # End of movement while loop\n",
    "    \n",
    "        # Check what was the reason of exiting the while loop and update the counters\n",
    "        if not caught_us and not caught_prey and time_steps[trial] == max_steps:\n",
    "            fail_hang[trial] = 1\n",
    "        if caught_us:\n",
    "            print(\"Predator Caught the Agent at location: \"+str(a.node))\n",
    "        elif caught_prey:\n",
    "            print(\"Agent Caught the Prey at location: \"+str(a.node))\n",
    "\n",
    "        print(\"Total timesteps: \"+str(time_steps[trial]))\n",
    "        print()\n",
    "\n",
    "        \n",
    "        file_name = \"./Graphs/graph\" + str(graph_number)  + \"/agent_csv/agent\" + str(agentNum) + agentChar + \"/path/Agent/Run\" + str(run) + \"/Trial\"+ str(trial)+'.pkl'\n",
    "    \n",
    "        with open(file_name, 'wb') as f:\n",
    "            loaded_dict = pickle.dump(agent_path[trial],f)\n",
    "\n",
    "        file_name = \"./Graphs/graph\" + str(graph_number)  + \"/agent_csv/agent\" + str(agentNum) + agentChar + \"/path/Prey/Run\" + str(run) + \"/Trial\"+ str(trial)+'.pkl'\n",
    "    \n",
    "        with open(file_name, 'wb') as f:\n",
    "            loaded_dict = pickle.dump(prey_path[trial],f)\n",
    "        \n",
    "        file_name = \"./Graphs/graph\" + str(graph_number)  + \"/agent_csv/agent\" + str(agentNum) + agentChar + \"/path/Predator/Run\" + str(run) + \"/Trial\"+ str(trial)+'.pkl'\n",
    "\n",
    "        with open(file_name, 'wb') as f:\n",
    "            loaded_dict = pickle.dump(predator_path[trial],f)\n",
    "\n",
    "    # End of all trials\n",
    "\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"success\"]= success.values()\n",
    "    df[\"failure_predator\"]= fail_predator.values()\n",
    "    df[\"failure_timeout\"]= fail_hang.values()\n",
    "    df[\"time_steps\"] = time_steps.values()\n",
    "\n",
    "    \n",
    "    file_name = \"./Graphs/graph\" + str(graph_number)  + \"/agent_csv/agent\" + str(agentNum) + agentChar + \"/data/Run\" + str(run) + '.csv'\n",
    "    df.to_csv(file_name, encoding='utf-8')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    total_success += sum(list(success.values()))\n",
    "\n",
    "    # df_2 = pd.DataFrame()\n",
    "    # df_2[\"times_prey_known\"] = times_prey_known.values()\n",
    "    # df_2[\"times_pred_known\"] = times_pred_known.values()\n",
    "    # df_2[\"time_steps\"] = time_steps.values()\n",
    "    # file_name_2 = \"./know_csv/agent\" + str(agentNum) + agentChar + \"/Run\" + str(run) + '.csv'\n",
    "    # df_2.to_csv(file_name_2, encoding='utf-8')\n",
    "\n",
    "# End of runs\n",
    "\n",
    "print(\"The total success percentage for the run was: [{}%]\".format((total_success * 100) / (num_runs * num_trials)))\n",
    "\n",
    "print(\"The time taken for {} runs ({} trials per run) was: [{}] seconds\".format(num_runs, num_trials, round(time.time() - start_time, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('the-circle-of-life-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f4ba500dd42b6450699ce905131b3c2df06583b0185a6a5365777224f23c62e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
